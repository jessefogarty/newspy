#!/usr/bin/env python3
import feedparser
from source import Source
from termcolor import cprint
import requests
import concurrent.futures

class Articles():
    '''
    '''
    
    def __init__(self, f:list) -> object:
        '''Finds new articles from Source.feeds object. \n
        Args: \n
            f(list) - a list object containing (str) feeds.
        Contains: \n
            article_list(list) - list of unique articles urls from f.
            articles(list)(dicr) - a list of individual article dicts containing parsed data.
        '''
        self.feeds = f
        self.article_list = self.retrieve()
        self.articles = self.download()
        '''with concurrent.futures.ThreadPoolExecutor(max_workers=30) as executor:
            futures = []
            for _url in self.article_list:
                futures.append(executor.submit(self.download, url=_url))
            for future in concurrent.futures.as_completed(futures):
                try:
                    self.articles.append(future.result())'''


    def __repr__(self):
        rep = f"""Article object contains the following:
        # of feeds = {len(self.feeds)}
        # of unique articles: {len(self.article_list)}
        # of downloaded articles: {len(self.articles)}"""
        return rep
        
    def download(self) -> list:
        '''Download the HTML of an article URL. \n
        Args:
            self.article_list - A list of new article URLs generated by Articles.retrieve() \n
        Returns:
            articles(list) - a list of articles with a dict of each article
        '''
        def _download(url):
            '''A function to download the html of a given article.
            '''
            article = {}
            response = requests.get(_url)
            article["url"] = response.url
            article["html"] = response.content
            return article

        _articles = []
        with concurrent.futures.ThreadPoolExecutor(max_workers=30) as executor:
            futures = []
            for _url in self.article_list:
                futures.append(executor.submit(_download, url=_url))
            for future in concurrent.futures.as_completed(futures):
                _articles.append(future.result())

        return _articles

        
    def retrieve(self) -> list:
        '''Parse a list of Source.feed strs.
        '''
        _articles = []
        #cprint("Finding new _articles and adding to source.", "yellow")
        for i in range(len(self.feeds)):
            if i == 0:
                data = feedparser.parse(self.feeds[i])
                entries = data.entries
                links = [l["link"] for l in entries]
                _articles.extend(links)
            else:
                data = feedparser.parse(self.feeds[i])
                entries = data.entries
                links = [l["link"] for l in entries]
                _articles.extend(l for l in links if l not in _articles)
        #cprint(f"Added {len(_articles)} to source.", "green")
        return _articles